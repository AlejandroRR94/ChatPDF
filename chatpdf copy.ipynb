{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.202\n"
     ]
    }
   ],
   "source": [
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b378a82d8f14eccb31d00b0c8be2396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device has 1 GPUs available. Provide device={deviceId} to `from_model_id` to use availableGPUs for execution. deviceId is -1 (default) for CPU and can be a positive integer associated with CUDA device id.\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for HuggingFacePipeline\ntrust_remote_code\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m MODEL_KWARGS \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtemperature\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m0.0\u001b[39m,\n\u001b[1;32m      2\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m2048\u001b[39m,\n\u001b[1;32m      3\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mdevice_map\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtrust_remote_code\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39moffload_folder\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39moffload_folder/\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m      7\u001b[0m MODEL_ID \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOpenAssistant/stablelm-7b-sft-v7-epoch-3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m llm \u001b[39m=\u001b[39m HuggingFacePipeline\u001b[39m.\u001b[39;49mfrom_model_id(model_id\u001b[39m=\u001b[39;49mMODEL_ID,\n\u001b[1;32m      9\u001b[0m                                         task\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-generation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m                                         model_kwargs\u001b[39m=\u001b[39;49mMODEL_KWARGS,\n\u001b[1;32m     11\u001b[0m                                         trust_remote_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\u001b[39m#>,\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m                                         \u001b[39m#device=(torch.cuda.device_count()-1)\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m                                         )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/langchain/llms/huggingface_pipeline.py:141\u001b[0m, in \u001b[0;36mHuggingFacePipeline.from_model_id\u001b[0;34m(cls, model_id, task, device, model_kwargs, pipeline_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mif\u001b[39;00m pipeline\u001b[39m.\u001b[39mtask \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m VALID_TASKS:\n\u001b[1;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    138\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot invalid task \u001b[39m\u001b[39m{\u001b[39;00mpipeline\u001b[39m.\u001b[39mtask\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcurrently only \u001b[39m\u001b[39m{\u001b[39;00mVALID_TASKS\u001b[39m}\u001b[39;00m\u001b[39m are supported\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m     )\n\u001b[0;32m--> 141\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    142\u001b[0m     pipeline\u001b[39m=\u001b[39;49mpipeline,\n\u001b[1;32m    143\u001b[0m     model_id\u001b[39m=\u001b[39;49mmodel_id,\n\u001b[1;32m    144\u001b[0m     model_kwargs\u001b[39m=\u001b[39;49m_model_kwargs,\n\u001b[1;32m    145\u001b[0m     pipeline_kwargs\u001b[39m=\u001b[39;49m_pipeline_kwargs,\n\u001b[1;32m    146\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    147\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/langchain/load/serializable.py:61\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     62\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for HuggingFacePipeline\ntrust_remote_code\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "MODEL_KWARGS = {\"temperature\":0.0,\n",
    "                \"max_length\":2048,\n",
    "                \"device_map\":\"auto\",\n",
    "                \"trust_remote_code\":True,\n",
    "                \"offload_folder\": \"offload_folder/\"}\n",
    "\n",
    "MODEL_ID = \"OpenAssistant/stablelm-7b-sft-v7-epoch-3\"\n",
    "llm = HuggingFacePipeline.from_model_id(model_id=MODEL_ID,\n",
    "                                        task=\"text-generation\",\n",
    "                                        model_kwargs=MODEL_KWARGS#,\n",
    "                                        #device=(torch.cuda.device_count()-1)\n",
    "                                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.tie_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

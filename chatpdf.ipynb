{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.cufft_plan_cache.max_split_size_mb = 16  # Ajusta el valor según tus necesidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda113_nocublaslt.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/arr/miniconda3/envs/llm/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 6.1\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda113_nocublaslt.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/arr/miniconda3/envs/llm/lib/libcudart.so.11.0'), PosixPath('/home/arr/miniconda3/envs/llm/lib/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db8ffc2a3ab4f02aabe0c70063f8d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device has 1 GPUs available. Provide device={deviceId} to `from_model_id` to use availableGPUs for execution. deviceId is -1 (default) for CPU and can be a positive integer associated with CUDA device id.\n"
     ]
    }
   ],
   "source": [
    "MODEL_KWARGS = {\"temperature\":0.0,\n",
    "                \"max_length\":2048,\n",
    "                \"device_map\":\"cuda\",\n",
    "                \"trust_remote_code\":True,\n",
    "                \"offload_folder\": \"offload_folder/\",\n",
    "                \"load_in_4bit\":True\n",
    "                }\n",
    "\n",
    "MODEL_ID = \"OpenAssistant/stablelm-7b-sft-v7-epoch-3\"\n",
    "# MODEL_ID = \"google/flan-t5-xl\"\n",
    "llm = HuggingFacePipeline.from_model_id(model_id=MODEL_ID,\n",
    "                                        task=\"text-generation\",\n",
    "                                        model_kwargs=MODEL_KWARGS\n",
    "                                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1060'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='NVIDIA GeForce GTX 1060', major=6, minor=1, total_memory=6072MB, multi_processor_count=10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, OnlinePDFLoader\n",
    "\n",
    "# Documento de Prueba de BS\n",
    "# loader = PyPDFLoader(\"CAST_FAQ_FISCAL_CAST_FAQ_FISCAL.PDF\")\n",
    "# pages = loader.load_and_split()\n",
    "\n",
    "# Archivo de prueba \n",
    "loader = OnlinePDFLoader(\"https://arxiv.org/pdf/1911.01547.pdf\")\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document = pages[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1995, which is longer than the specified 1024\n",
      "Created a chunk of size 1435, which is longer than the specified 1024\n",
      "Created a chunk of size 1167, which is longer than the specified 1024\n",
      "Created a chunk of size 1342, which is longer than the specified 1024\n",
      "Created a chunk of size 1037, which is longer than the specified 1024\n",
      "Created a chunk of size 1484, which is longer than the specified 1024\n",
      "Created a chunk of size 1057, which is longer than the specified 1024\n",
      "Created a chunk of size 1044, which is longer than the specified 1024\n",
      "Created a chunk of size 1120, which is longer than the specified 1024\n",
      "Created a chunk of size 1268, which is longer than the specified 1024\n",
      "Created a chunk of size 1464, which is longer than the specified 1024\n",
      "Created a chunk of size 1898, which is longer than the specified 1024\n",
      "Created a chunk of size 1066, which is longer than the specified 1024\n",
      "Created a chunk of size 1506, which is longer than the specified 1024\n",
      "Created a chunk of size 1270, which is longer than the specified 1024\n",
      "Created a chunk of size 1309, which is longer than the specified 1024\n",
      "Created a chunk of size 1160, which is longer than the specified 1024\n",
      "Created a chunk of size 1121, which is longer than the specified 1024\n",
      "Created a chunk of size 1060, which is longer than the specified 1024\n",
      "Created a chunk of size 1103, which is longer than the specified 1024\n",
      "Created a chunk of size 1164, which is longer than the specified 1024\n",
      "Created a chunk of size 1319, which is longer than the specified 1024\n",
      "Created a chunk of size 1148, which is longer than the specified 1024\n",
      "Created a chunk of size 1119, which is longer than the specified 1024\n",
      "Created a chunk of size 1080, which is longer than the specified 1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
    "\n",
    "documents = text_splitter.split_documents(document)\n",
    "\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To make deliberate progress towards more intelligent and more human-like artiﬁcial systems, we need to be following an appropriate feedback signal: we need to be able to deﬁne and evaluate intelligence in a way that enables comparisons between two systems, as well as comparisons with humans. Over the past hundred years, there has been an abun- dance of attempts to deﬁne and measure intelligence, across both the ﬁelds of psychology and AI. We summarize and critically assess these deﬁnitions and evaluation approaches, while making apparent the two historical conceptions of intelligence that have implicitly guided them. We note that in practice, the contemporary AI community still gravitates to- wards benchmarking intelligence by comparing the skill exhibited by AIs and humans at speciﬁc tasks, such as board games and video games. We argue that solely measuring skill at any given task falls short of measuring intelligence, because skill is heavily modulated by prior knowledge and experience: unlimited priors or unlimited training data allow ex- perimenters to “buy” arbitrary levels of skills for a system, in a way that masks the system’s own generalization power. We then articulate a new formal deﬁnition of intelligence based on Algorithmic Information Theory, describing intelligence as skill-acquisition efﬁciency and highlighting the concepts of scope, generalization difﬁculty, priors, and experience, as critical pieces to be accounted for in characterizing intelligent systems. Using this deﬁ- nition, we propose a set of guidelines for what a general AI benchmark should look like. Finally, we present a new benchmark closely following these guidelines, the Abstraction and Reasoning Corpus (ARC), built upon an explicit set of priors designed to be as close as possible to innate human priors. We argue that ARC can be used to measure a human-like form of general ﬂuid intelligence and that it enables fair general intelligence comparisons between AI systems and humans.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03373878821730614,\n",
       " 0.02905896119773388,\n",
       " -0.019138799980282784,\n",
       " -0.014761287719011307,\n",
       " -0.028279926627874374,\n",
       " 0.0102404048666358,\n",
       " 0.06609061360359192,\n",
       " 0.006109553389251232,\n",
       " 0.027785753831267357,\n",
       " 0.018225178122520447,\n",
       " 0.023087017238140106,\n",
       " 0.03958410769701004,\n",
       " 0.01580357365310192,\n",
       " -0.0019699351396411657,\n",
       " 0.06493435800075531,\n",
       " -0.02838227152824402,\n",
       " 0.010179935023188591,\n",
       " -0.01684015803039074,\n",
       " 0.035411447286605835,\n",
       " 0.010596830397844315,\n",
       " -0.08267834782600403,\n",
       " -0.026269562542438507,\n",
       " -0.010729643516242504,\n",
       " 0.010143139399588108,\n",
       " 0.032705359160900116,\n",
       " -0.029204027727246284,\n",
       " 0.059680696576833725,\n",
       " -0.0436161570250988,\n",
       " 0.008716690354049206,\n",
       " -0.04567641019821167,\n",
       " -0.010140769183635712,\n",
       " 0.01431471761316061,\n",
       " -0.07532326132059097,\n",
       " 0.013199925422668457,\n",
       " 1.9213789528294e-06,\n",
       " -0.05154431238770485,\n",
       " 0.007004035636782646,\n",
       " -0.0055690910667181015,\n",
       " -0.008541214279830456,\n",
       " -0.013718556612730026,\n",
       " 0.03164663910865784,\n",
       " 0.06817618012428284,\n",
       " -0.004560365341603756,\n",
       " 0.014185692183673382,\n",
       " -0.030293582007288933,\n",
       " 0.040322139859199524,\n",
       " -0.05723216012120247,\n",
       " -0.026537248864769936,\n",
       " -0.0073336209170520306,\n",
       " -0.004510986153036356,\n",
       " 0.014450672082602978,\n",
       " 0.03890727460384369,\n",
       " 0.036400411278009415,\n",
       " -0.044705551117658615,\n",
       " 0.02698255516588688,\n",
       " 0.03136414662003517,\n",
       " 0.008665941655635834,\n",
       " 0.015074091963469982,\n",
       " -0.03445294126868248,\n",
       " 0.014835938811302185,\n",
       " -0.015491927042603493,\n",
       " 0.012090353295207024,\n",
       " 0.015960171818733215,\n",
       " -0.018883060663938522,\n",
       " -0.0031460528261959553,\n",
       " -0.02488417737185955,\n",
       " 0.054183151572942734,\n",
       " 0.016997195780277252,\n",
       " 0.010323693975806236,\n",
       " -0.03409499675035477,\n",
       " 0.04218923673033714,\n",
       " 0.04196791723370552,\n",
       " -0.006958877667784691,\n",
       " 0.08878636360168457,\n",
       " 0.037722617387771606,\n",
       " -0.010338600724935532,\n",
       " -0.057341068983078,\n",
       " -0.018202796578407288,\n",
       " 0.00760649424046278,\n",
       " -0.05658085271716118,\n",
       " 0.007404649164527655,\n",
       " 0.0720440223813057,\n",
       " -0.009843403473496437,\n",
       " 0.007020290475338697,\n",
       " -0.003958536311984062,\n",
       " 0.06351394951343536,\n",
       " 0.034416455775499344,\n",
       " -0.005286813713610172,\n",
       " -0.008966744877398014,\n",
       " -0.031675633043050766,\n",
       " -0.007377279456704855,\n",
       " -0.03356551006436348,\n",
       " -0.027123531326651573,\n",
       " 0.042524732649326324,\n",
       " -0.013678470626473427,\n",
       " -0.03799724578857422,\n",
       " 0.05485398694872856,\n",
       " -0.02936733514070511,\n",
       " 0.019291095435619354,\n",
       " 0.004621768835932016,\n",
       " 0.007369800470769405,\n",
       " -0.012982524931430817,\n",
       " 0.06455289572477341,\n",
       " 0.056397177278995514,\n",
       " 0.003930475562810898,\n",
       " 0.06823880225419998,\n",
       " 0.016109373420476913,\n",
       " 0.05211808905005455,\n",
       " -0.042978160083293915,\n",
       " 0.04380117729306221,\n",
       " -0.04936523735523224,\n",
       " -0.01359183806926012,\n",
       " 0.007344990037381649,\n",
       " 0.008210171945393085,\n",
       " 0.08438906818628311,\n",
       " -0.0028257647063583136,\n",
       " -0.05700617656111717,\n",
       " -0.04151218757033348,\n",
       " -0.045022763311862946,\n",
       " 0.0023181054275482893,\n",
       " -0.09455310553312302,\n",
       " -0.002696199808269739,\n",
       " 0.006645973771810532,\n",
       " -0.01927500218153,\n",
       " -0.03719734027981758,\n",
       " 0.010666332207620144,\n",
       " -0.049077801406383514,\n",
       " 0.030461428686976433,\n",
       " -0.02000146359205246,\n",
       " 0.029629569500684738,\n",
       " -0.00023528565361630172,\n",
       " 0.022749904543161392,\n",
       " 0.01085344422608614,\n",
       " 0.012072838842868805,\n",
       " 0.016776010394096375,\n",
       " 0.10385206341743469,\n",
       " 0.015942756086587906,\n",
       " -0.05384402349591255,\n",
       " 0.013025276362895966,\n",
       " -0.04185277223587036,\n",
       " 0.02912970818579197,\n",
       " -0.03983553126454353,\n",
       " 0.017008211463689804,\n",
       " -0.05760255828499794,\n",
       " 0.005222327075898647,\n",
       " 0.024206826463341713,\n",
       " 0.01830967329442501,\n",
       " -0.07407286763191223,\n",
       " -0.021721893921494484,\n",
       " -0.01434009987860918,\n",
       " -0.014587176963686943,\n",
       " -0.021389955654740334,\n",
       " -0.025807678699493408,\n",
       " 0.02542254328727722,\n",
       " 0.028154246509075165,\n",
       " 0.04819084331393242,\n",
       " -0.02491939812898636,\n",
       " 0.030978024005889893,\n",
       " 0.03734278306365013,\n",
       " -0.04396674036979675,\n",
       " 0.0489133782684803,\n",
       " 0.009321695193648338,\n",
       " 0.035195644944906235,\n",
       " -0.012949875555932522,\n",
       " -0.00194400898180902,\n",
       " 0.00240350142121315,\n",
       " 0.021582162007689476,\n",
       " -0.007976914756000042,\n",
       " -0.009958261623978615,\n",
       " -0.016772646456956863,\n",
       " 0.009496781975030899,\n",
       " 0.0018133156700059772,\n",
       " -0.025507183745503426,\n",
       " 0.0313495397567749,\n",
       " 0.024958042427897453,\n",
       " 0.09507028758525848,\n",
       " 0.007599845994263887,\n",
       " 0.03610436990857124,\n",
       " -0.007080725394189358,\n",
       " 0.00296788290143013,\n",
       " 0.029685664921998978,\n",
       " 0.03659059479832649,\n",
       " -0.01404122356325388,\n",
       " 0.036930229514837265,\n",
       " -0.04858170077204704,\n",
       " -0.0035869437269866467,\n",
       " 0.01731843873858452,\n",
       " 0.04335969313979149,\n",
       " -0.03339181840419769,\n",
       " -0.04038608446717262,\n",
       " 0.010326460935175419,\n",
       " 0.019558604806661606,\n",
       " 0.02306217886507511,\n",
       " 0.0057065426371991634,\n",
       " 0.03953501209616661,\n",
       " -0.013575825840234756,\n",
       " 0.026090271770954132,\n",
       " -0.08687105774879456,\n",
       " -0.005633750464767218,\n",
       " 0.016129834577441216,\n",
       " -0.036511365324258804,\n",
       " -0.046416059136390686,\n",
       " 0.03416413813829422,\n",
       " 0.00013988374848850071,\n",
       " -0.01906503178179264,\n",
       " -0.0009216013131663203,\n",
       " 0.019734367728233337,\n",
       " 0.013099964708089828,\n",
       " -0.0012961621396243572,\n",
       " -0.014180188067257404,\n",
       " 0.008178693242371082,\n",
       " -0.021772991865873337,\n",
       " 0.022798685356974602,\n",
       " 0.007281923200935125,\n",
       " -0.01679408736526966,\n",
       " 0.001764334854669869,\n",
       " 0.033518556505441666,\n",
       " -0.008824729360640049,\n",
       " -0.041417382657527924,\n",
       " 0.039085689932107925,\n",
       " 0.018062518909573555,\n",
       " 0.025716057047247887,\n",
       " -0.014503208920359612,\n",
       " -0.01525183580815792,\n",
       " -0.021397441625595093,\n",
       " -0.019474506378173828,\n",
       " -0.053800318390131,\n",
       " -0.017016107216477394,\n",
       " 0.05000075325369835,\n",
       " -0.006376062985509634,\n",
       " -0.008141493424773216,\n",
       " 0.016913853585720062,\n",
       " 0.0037845561746507883,\n",
       " -0.034443777054548264,\n",
       " -0.02371780388057232,\n",
       " 0.01749078556895256,\n",
       " 0.05735601857304573,\n",
       " 0.10328143835067749,\n",
       " -0.003814206225797534,\n",
       " -0.0880986675620079,\n",
       " 0.01089125033468008,\n",
       " 0.009384277276694775,\n",
       " 0.05362902581691742,\n",
       " 0.0018803903367370367,\n",
       " 0.027578599750995636,\n",
       " -0.04739942029118538,\n",
       " 0.03366811200976372,\n",
       " 0.03878360614180565,\n",
       " 0.04552309587597847,\n",
       " -0.040968772023916245,\n",
       " -0.014710447750985622,\n",
       " -0.009243418462574482,\n",
       " 0.046220917254686356,\n",
       " -0.021032825112342834,\n",
       " 0.05856576934456825,\n",
       " -0.01888319104909897,\n",
       " -0.05649761110544205,\n",
       " 0.049026284366846085,\n",
       " -0.01728709414601326,\n",
       " 0.04325859621167183,\n",
       " -0.07025586813688278,\n",
       " -0.012279589660465717,\n",
       " 0.007456428837031126,\n",
       " -0.005754763260483742,\n",
       " 0.06122688576579094,\n",
       " -0.015164892189204693,\n",
       " -0.03321962058544159,\n",
       " -0.026064295321702957,\n",
       " -0.013692223466932774,\n",
       " -0.014830938540399075,\n",
       " 0.03861474245786667,\n",
       " -0.010799727402627468,\n",
       " -0.022890696302056313,\n",
       " -0.009057232178747654,\n",
       " 0.030564095824956894,\n",
       " 0.011525813490152359,\n",
       " -0.0005852741887792945,\n",
       " 0.05961509048938751,\n",
       " 0.0203825905919075,\n",
       " 0.0172270555049181,\n",
       " -0.018123595044016838,\n",
       " -0.016812339425086975,\n",
       " -0.0019948133267462254,\n",
       " -0.026433143764734268,\n",
       " -0.04109213873744011,\n",
       " 0.029657967388629913,\n",
       " 0.04986947402358055,\n",
       " 0.021405231207609177,\n",
       " 0.0393277183175087,\n",
       " -0.026047972962260246,\n",
       " -0.07072383165359497,\n",
       " -0.002860088599845767,\n",
       " -0.03182924911379814,\n",
       " -0.030934317037463188,\n",
       " 0.0498499721288681,\n",
       " 0.0050214724615216255,\n",
       " -0.0024161101318895817,\n",
       " 0.07100266963243484,\n",
       " 0.03833372890949249,\n",
       " 0.030201999470591545,\n",
       " -0.0028495844453573227,\n",
       " 0.017045965418219566,\n",
       " -0.008700813166797161,\n",
       " -0.006541240494698286,\n",
       " -0.0013260066043585539,\n",
       " 0.06677458435297012,\n",
       " -0.043454527854919434,\n",
       " -0.058187246322631836,\n",
       " -0.015749650076031685,\n",
       " 0.04576241225004196,\n",
       " -0.017573682591319084,\n",
       " -0.009450390003621578,\n",
       " 0.02733626589179039,\n",
       " 0.12567387521266937,\n",
       " -0.050609786063432693,\n",
       " -0.022486934438347816,\n",
       " -0.055815018713474274,\n",
       " -0.010721823200583458,\n",
       " 0.00946580246090889,\n",
       " 0.09131544083356857,\n",
       " -0.002094544470310211,\n",
       " -0.01600017212331295,\n",
       " -0.006381208077073097,\n",
       " 0.004890308249741793,\n",
       " 0.026901910081505775,\n",
       " -0.011719945818185806,\n",
       " -0.014524051919579506,\n",
       " 0.016955822706222534,\n",
       " 0.061066605150699615,\n",
       " 0.021074609830975533,\n",
       " -0.0012065416667610407,\n",
       " -0.06875664740800858,\n",
       " -0.02518497221171856,\n",
       " -0.06916935741901398,\n",
       " 0.01078121829777956,\n",
       " 0.0050682867877185345,\n",
       " -0.04582098871469498,\n",
       " -0.0025315089151263237,\n",
       " 0.01159025076776743,\n",
       " -0.03827057033777237,\n",
       " -0.011806421913206577,\n",
       " -0.0058248890563845634,\n",
       " -0.007831563241779804,\n",
       " 0.03813394904136658,\n",
       " -0.007703233975917101,\n",
       " 0.010370960459113121,\n",
       " 0.07483784854412079,\n",
       " -0.07387319207191467,\n",
       " -0.023850390687584877,\n",
       " -0.0458688922226429,\n",
       " 0.06291012465953827,\n",
       " -0.0031961570493876934,\n",
       " 0.015833042562007904,\n",
       " -0.024089818820357323,\n",
       " 0.02250063605606556,\n",
       " -0.04079420119524002,\n",
       " 0.021786317229270935,\n",
       " 0.048628441989421844,\n",
       " 0.026775097474455833,\n",
       " -0.051907382905483246,\n",
       " 0.023250889033079147,\n",
       " 0.023412350565195084,\n",
       " -0.0112962257117033,\n",
       " 0.013520332053303719,\n",
       " 0.06345560401678085,\n",
       " 0.005247736349701881,\n",
       " 0.0267996396869421,\n",
       " 0.006891483440995216,\n",
       " -0.00555823091417551,\n",
       " -0.0035698709543794394,\n",
       " 0.04998375102877617,\n",
       " -0.02368842251598835,\n",
       " -0.005689532961696386,\n",
       " 0.05206674337387085,\n",
       " 0.021146664395928383,\n",
       " 0.007877458818256855,\n",
       " 0.006114366929978132,\n",
       " 0.02409033291041851,\n",
       " -0.0419246144592762,\n",
       " 0.02733169123530388,\n",
       " 0.0287204347550869,\n",
       " 0.002535860054194927,\n",
       " 0.05598054453730583,\n",
       " -0.0196578036993742,\n",
       " 0.014821166172623634,\n",
       " -0.0527065210044384,\n",
       " -0.04182678461074829,\n",
       " 0.0032754375133663416,\n",
       " -0.05577874183654785,\n",
       " -0.0129029406234622,\n",
       " 0.005642334930598736,\n",
       " -0.03146909922361374,\n",
       " -0.059804268181324005,\n",
       " 0.022715866565704346,\n",
       " -0.009291913360357285,\n",
       " 0.0004292102821636945,\n",
       " -0.05991214141249657,\n",
       " -0.005578815937042236,\n",
       " 0.006518350914120674,\n",
       " 0.01559985987842083,\n",
       " -0.020171334967017174,\n",
       " -0.060264088213443756,\n",
       " 0.014867361634969711,\n",
       " 0.04168829321861267,\n",
       " -0.002618182683363557,\n",
       " -0.0037271634209901094,\n",
       " 0.018525639548897743,\n",
       " -0.003119288943707943,\n",
       " -0.04509905353188515,\n",
       " -0.07448269426822662,\n",
       " -0.04222070425748825,\n",
       " -0.0068237013183534145,\n",
       " -0.03733920678496361,\n",
       " 0.025944223627448082,\n",
       " 0.044571634382009506,\n",
       " -0.02506241761147976,\n",
       " -0.002324687549844384,\n",
       " -0.07277368009090424,\n",
       " -0.018417324870824814,\n",
       " 0.06746373325586319,\n",
       " 0.039474718272686005,\n",
       " 0.08646884560585022,\n",
       " -0.0009356529917567968,\n",
       " 0.02761792577803135,\n",
       " -0.03604718670248985,\n",
       " -0.020851900801062584,\n",
       " -0.019900333136320114,\n",
       " -0.005240082275122404,\n",
       " 0.03543110564351082,\n",
       " 0.010476667433977127,\n",
       " -0.024127626791596413,\n",
       " 0.015133277513086796,\n",
       " -0.04413523152470589,\n",
       " -0.02318618819117546,\n",
       " -0.04686298221349716,\n",
       " -0.08233873546123505,\n",
       " 0.035094041377305984,\n",
       " 0.04576132446527481,\n",
       " -0.013557515107095242,\n",
       " -0.05939408764243126,\n",
       " -0.03211778774857521,\n",
       " 0.016992725431919098,\n",
       " 0.10132754594087601,\n",
       " 0.019094321876764297,\n",
       " -0.04330119490623474,\n",
       " -0.04451477900147438,\n",
       " 0.004883905872702599,\n",
       " -0.030359407886862755,\n",
       " -0.012287494726479053,\n",
       " 0.03424156829714775,\n",
       " -0.03896087408065796,\n",
       " -0.06455715745687485,\n",
       " -0.024932660162448883,\n",
       " -0.03455289825797081,\n",
       " 0.00368567556142807,\n",
       " -0.04379457235336304,\n",
       " -0.01693318411707878,\n",
       " 0.006575042847543955,\n",
       " -0.0019339642021805048,\n",
       " 0.021189315244555473,\n",
       " 0.07174873352050781,\n",
       " 0.04280216991901398,\n",
       " -0.04131447523832321,\n",
       " -0.022770216688513756,\n",
       " 0.0405680350959301,\n",
       " 0.051664866507053375,\n",
       " -0.020601896569132805,\n",
       " -0.020895924419164658,\n",
       " 0.05030643939971924,\n",
       " 0.0025005624629557133,\n",
       " -0.028882669284939766,\n",
       " -0.015369687229394913,\n",
       " -0.009307839907705784,\n",
       " -0.009160690009593964,\n",
       " 0.07055579125881195,\n",
       " -0.006407652050256729,\n",
       " 0.021720005199313164,\n",
       " -0.043298229575157166,\n",
       " -0.03506208583712578,\n",
       " -0.0052602835930883884,\n",
       " -0.0013171184109523892,\n",
       " 0.04187856242060661,\n",
       " 0.02269534394145012,\n",
       " 0.008716728538274765,\n",
       " 0.030613839626312256,\n",
       " -0.040967222303152084,\n",
       " -0.02770109660923481,\n",
       " -0.0425649955868721,\n",
       " -0.009278999641537666,\n",
       " -0.049893591552972794,\n",
       " -0.019210880622267723,\n",
       " 0.02305232360959053,\n",
       " 0.0039031761698424816,\n",
       " -0.013650253415107727,\n",
       " 0.01887749508023262,\n",
       " -0.008323566988110542,\n",
       " -0.050698019564151764,\n",
       " 0.011628258042037487,\n",
       " -0.0539063960313797,\n",
       " -0.0065598264336586,\n",
       " -0.01824973151087761,\n",
       " 0.011048478074371815,\n",
       " 0.001888537546619773,\n",
       " 0.01738324947655201,\n",
       " -0.02002876251935959,\n",
       " 0.047867514193058014,\n",
       " 0.06450222432613373,\n",
       " 0.05366339161992073,\n",
       " -0.007105624303221703,\n",
       " 0.01568089984357357,\n",
       " -0.007937727496027946,\n",
       " 0.012170856818556786,\n",
       " -0.08636119216680527,\n",
       " -0.09063755720853806,\n",
       " 0.013713653199374676,\n",
       " 0.0673074796795845,\n",
       " -0.04322335124015808,\n",
       " 0.017337286844849586,\n",
       " -0.0056010340340435505,\n",
       " -0.021297698840498924,\n",
       " -0.005186004098504782,\n",
       " -0.016741063445806503,\n",
       " -0.023464571684598923,\n",
       " -0.017635127529501915,\n",
       " -0.02750377729535103,\n",
       " -0.009678329341113567,\n",
       " 0.013824313879013062,\n",
       " 0.03130343183875084,\n",
       " 0.023419881239533424,\n",
       " 0.0336507149040699,\n",
       " -0.056475188583135605,\n",
       " -0.000617414596490562,\n",
       " -0.023870641365647316,\n",
       " -0.02037966623902321,\n",
       " -0.03449022024869919,\n",
       " -0.006919512525200844,\n",
       " -0.007380434777587652,\n",
       " 0.04045955091714859,\n",
       " 0.023431578651070595,\n",
       " 0.012320118024945259,\n",
       " -0.087761290371418,\n",
       " -0.03666446730494499,\n",
       " 0.0074962289072573185,\n",
       " 0.03599034249782562,\n",
       " 0.07213300466537476,\n",
       " 0.05122130364179611,\n",
       " -0.05384129658341408,\n",
       " 0.03086196631193161,\n",
       " -0.009019788354635239,\n",
       " -0.0014179612044245005,\n",
       " 0.007835423573851585,\n",
       " -0.01718374900519848,\n",
       " -0.12509022653102875,\n",
       " -0.029362602159380913,\n",
       " -0.011686805635690689,\n",
       " -6.0959733787262536e-33,\n",
       " -0.041418757289648056,\n",
       " -0.05834069848060608,\n",
       " 0.03470444306731224,\n",
       " 0.018380530178546906,\n",
       " 0.004870929289609194,\n",
       " -0.0158337764441967,\n",
       " -0.009335028938949108,\n",
       " 0.042562294751405716,\n",
       " -0.09808283299207687,\n",
       " 0.0014779387274757028,\n",
       " -0.013576691970229149,\n",
       " 0.011803070083260536,\n",
       " -0.010321367532014847,\n",
       " -0.034045495092868805,\n",
       " 0.04621858894824982,\n",
       " 0.047378864139318466,\n",
       " -0.010918905027210712,\n",
       " -0.008991915732622147,\n",
       " -0.03702429682016373,\n",
       " -0.012424576096236706,\n",
       " 0.015844663605093956,\n",
       " -0.03589824214577675,\n",
       " 0.016913648694753647,\n",
       " -0.04959827661514282,\n",
       " 0.020757365971803665,\n",
       " -0.02812621369957924,\n",
       " 0.027073953300714493,\n",
       " -0.01704525016248226,\n",
       " 0.002900782972574234,\n",
       " 0.007061227224767208,\n",
       " -0.020575422793626785,\n",
       " 0.007071696687489748,\n",
       " 0.028442518785595894,\n",
       " -0.02594847045838833,\n",
       " 0.003717410610988736,\n",
       " -0.01091533899307251,\n",
       " 0.0001462522050132975,\n",
       " -0.05972724407911301,\n",
       " -0.015657741576433182,\n",
       " -0.05213451385498047,\n",
       " -0.014323044568300247,\n",
       " -0.08784649521112442,\n",
       " 0.004374396055936813,\n",
       " 0.017613522708415985,\n",
       " -0.04286763444542885,\n",
       " -0.08457881212234497,\n",
       " 0.059280719608068466,\n",
       " 0.027238359674811363,\n",
       " 0.0068195657804608345,\n",
       " -0.005837886594235897,\n",
       " -0.011534626595675945,\n",
       " 0.002475960645824671,\n",
       " -0.06382886320352554,\n",
       " -0.0025594562757760286,\n",
       " -0.08130521327257156,\n",
       " -0.012505055405199528,\n",
       " 0.006962632294744253,\n",
       " -0.06952100247144699,\n",
       " 0.0024821253027766943,\n",
       " 0.05164173245429993,\n",
       " -0.013380988501012325,\n",
       " 0.0180257186293602,\n",
       " -0.021518219262361526,\n",
       " -0.04905131831765175,\n",
       " 0.016205191612243652,\n",
       " 0.03797280788421631,\n",
       " 0.05573170259594917,\n",
       " 0.015422087162733078,\n",
       " 0.047580212354660034,\n",
       " -0.04023386910557747,\n",
       " 0.04947352036833763,\n",
       " 0.02996402233839035,\n",
       " 0.06107430160045624,\n",
       " -0.029712392017245293,\n",
       " 0.020670022815465927,\n",
       " -0.024624457582831383,\n",
       " -0.019350508227944374,\n",
       " -0.010333739221096039,\n",
       " 0.06486319750547409,\n",
       " 0.012405384331941605,\n",
       " -0.043773338198661804,\n",
       " -0.04458678886294365,\n",
       " -0.05494556576013565,\n",
       " 0.008087100461125374,\n",
       " 0.05227431654930115,\n",
       " -0.02696252055466175,\n",
       " 0.008725574240088463,\n",
       " -0.005967885255813599,\n",
       " 0.0155530646443367,\n",
       " -0.018097763881087303,\n",
       " 0.04557226598262787,\n",
       " -0.006484328303486109,\n",
       " 0.030593391507864,\n",
       " -0.002340187318623066,\n",
       " 0.017550397664308548,\n",
       " -0.012700701132416725,\n",
       " 0.011073112487792969,\n",
       " 0.025402246043086052,\n",
       " 0.017709869891405106,\n",
       " -0.004588632844388485,\n",
       " 0.00021774096239823848,\n",
       " 0.0002010341122513637,\n",
       " -0.001195918070152402,\n",
       " 0.051657162606716156,\n",
       " 0.07502159476280212,\n",
       " -0.009948208928108215,\n",
       " 0.015313936397433281,\n",
       " -0.0021708786953240633,\n",
       " -0.025701230391860008,\n",
       " -0.05308888852596283,\n",
       " 0.023281356319785118,\n",
       " 0.007635597605258226,\n",
       " 0.04974694177508354,\n",
       " -0.07493475079536438,\n",
       " 0.0199002493172884,\n",
       " -0.024363921955227852,\n",
       " 0.0022867440711706877,\n",
       " -0.10615358501672745,\n",
       " -0.00037593540037050843,\n",
       " -0.02760825864970684,\n",
       " -0.03886019065976143,\n",
       " 0.031140299513936043,\n",
       " -0.02654358558356762,\n",
       " -0.021716022863984108,\n",
       " -0.00572375301271677,\n",
       " -0.006764317397028208,\n",
       " -0.012917626649141312,\n",
       " -0.006963842548429966,\n",
       " -0.05771409347653389,\n",
       " -0.005904267076402903,\n",
       " -0.017039064317941666,\n",
       " -0.023091427981853485,\n",
       " 2.602687914077251e-07,\n",
       " -0.008977081626653671,\n",
       " 0.04636424407362938,\n",
       " -0.016596594825387,\n",
       " -0.02440479025244713,\n",
       " 0.007810566108673811,\n",
       " -0.014628062956035137,\n",
       " -0.043282847851514816,\n",
       " 0.04046274349093437,\n",
       " 0.06409148126840591,\n",
       " 0.045841801911592484,\n",
       " 0.007482191547751427,\n",
       " -0.014311634935438633,\n",
       " -0.010467867366969585,\n",
       " -0.024471746757626534,\n",
       " -0.004771583713591099,\n",
       " -0.05461178719997406,\n",
       " 0.013920520432293415,\n",
       " 0.020584750920534134,\n",
       " -0.008534722030162811,\n",
       " 0.015886493027210236,\n",
       " 0.050811659544706345,\n",
       " -0.053424056619405746,\n",
       " 0.01845315657556057,\n",
       " 0.004394881427288055,\n",
       " -0.01165371760725975,\n",
       " -0.06567660719156265,\n",
       " -0.034701306372880936,\n",
       " 0.007808488328009844,\n",
       " 0.06333651393651962,\n",
       " 0.0017129366751760244,\n",
       " 0.08233970403671265,\n",
       " 0.023465391248464584,\n",
       " -0.005463324021548033,\n",
       " 0.08643730729818344,\n",
       " 0.008605684153735638,\n",
       " 0.010234561748802662,\n",
       " -0.0005667987861670554,\n",
       " 0.021769732236862183,\n",
       " 0.03200043737888336,\n",
       " 0.11167312413454056,\n",
       " -0.002348220208659768,\n",
       " 0.007254428695887327,\n",
       " 0.03509560227394104,\n",
       " 0.020830292254686356,\n",
       " 0.0616818442940712,\n",
       " 0.00402081897482276,\n",
       " -0.0592779666185379,\n",
       " 0.009513375349342823,\n",
       " -0.07861270010471344,\n",
       " 0.023670384660363197,\n",
       " 0.006190126296132803,\n",
       " 0.07011422514915466,\n",
       " -0.02901075780391693,\n",
       " 0.016893425956368446,\n",
       " 0.023945748805999756,\n",
       " -0.03903945907950401,\n",
       " 0.05737690627574921,\n",
       " -0.005808830726891756,\n",
       " 0.014189859852194786,\n",
       " 0.03698934614658356,\n",
       " 0.003965090494602919,\n",
       " -0.12506413459777832,\n",
       " -0.01304311491549015,\n",
       " 0.054382096976041794,\n",
       " 0.04275018349289894,\n",
       " -0.013889189809560776,\n",
       " -0.030164755880832672,\n",
       " 2.1783292444954165e-34,\n",
       " -0.0020263646729290485,\n",
       " -0.003667624667286873,\n",
       " 0.021263642236590385,\n",
       " -0.0694844126701355,\n",
       " 0.032620012760162354,\n",
       " -0.02073531039059162,\n",
       " 0.0065220738761126995,\n",
       " -0.011524071916937828,\n",
       " 0.046981081366539,\n",
       " -0.02958875149488449,\n",
       " -0.0028621924575418234]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "query_result = embeddings.embed_query(documents[0].page_content)\n",
    "\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFacePipeline(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7fbd38e7f2d0>, model_id='OpenAssistant/stablelm-7b-sft-v7-epoch-3', model_kwargs={'temperature': 0.0, 'max_length': 2048, 'device_map': 'cuda', 'offload_folder': 'offload_folder/', 'load_in_4bit': True}, pipeline_kwargs={})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_20007/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">4225333923.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_20007/4225333923.py'</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/langchain/vectorstores/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">chroma.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">446</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_documents</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">443 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">444 │   │   </span>texts = [doc.page_content <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> doc <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> documents]                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">445 │   │   </span>metadatas = [doc.metadata <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> doc <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> documents]                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>446 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>.from_texts(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">447 │   │   │   </span>texts=texts,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">448 │   │   │   </span>embedding=embedding,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">449 │   │   │   </span>metadatas=metadatas,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/langchain/vectorstores/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">chroma.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">414</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_texts</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">411 │   │   │   </span>client_settings=client_settings,                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">412 │   │   │   </span>client=client,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">413 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>414 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">415 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> chroma_collection                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">416 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">417 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@classmethod</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/langchain/vectorstores/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">chroma.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">159</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">add_texts</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">156 │   │   │   </span>ids = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(uuid.uuid1()) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> _ <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> texts]                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 │   │   </span>embeddings = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._embedding_function <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>159 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>embeddings = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._embedding_function.embed_documents(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(texts))             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._collection.add(                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 │   │   │   </span>metadatas=metadatas, embeddings=embeddings, documents=texts, ids=ids           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/langchain/embeddings/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">huggingface.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">embed_documents</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 75 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">List of embeddings, one for each text.</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 76 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 77 │   │   </span>texts = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">map</span>(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span> x: x.replace(<span style=\"color: #808000; text-decoration-color: #808000\">\"\\n\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\" \"</span>), texts))                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 78 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>embeddings = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.client.encode(texts, **<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.encode_kwargs)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 79 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> embeddings.tolist()                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 80 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 81 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">embed_query</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, text: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>) -&gt; List[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">float</span>]:                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/sentence_transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">SentenceTransfo</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">rmer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">165</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">encode</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 │   │   │   </span>features = batch_to_device(features, device)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>165 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>out_features = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.forward(features)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 │   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> output_value == <span style=\"color: #808000; text-decoration-color: #808000\">'token_embeddings'</span>:                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 │   │   │   │   │   </span>embeddings = []                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">container.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">217</span> in  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214 │   # with Any as TorchScript expects a more precise type</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">215 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>):                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">216 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>217 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span> = module(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">218 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">220 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">append</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, module: Module) -&gt; <span style=\"color: #808000; text-decoration-color: #808000\">'Sequential'</span>:                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/sentence_transformers/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Transfor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">mer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">66</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 63 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">'token_type_ids'</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> features:                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 64 │   │   │   </span>trans_features[<span style=\"color: #808000; text-decoration-color: #808000\">'token_type_ids'</span>] = features[<span style=\"color: #808000; text-decoration-color: #808000\">'token_type_ids'</span>]                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 65 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 66 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.auto_model(**trans_features, return_dict=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 67 │   │   </span>output_tokens = output_states[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 68 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 69 │   │   </span>features.update({<span style=\"color: #808000; text-decoration-color: #808000\">'token_embeddings'</span>: output_tokens, <span style=\"color: #808000; text-decoration-color: #808000\">'attention_mask'</span>: features[<span style=\"color: #808000; text-decoration-color: #808000\">'</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/models/mpnet/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_mp</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">net.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">550</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 547 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 548 │   │   </span>head_mask = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.get_head_mask(head_mask, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.num_hidden_layers)          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 549 │   │   </span>embedding_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embeddings(input_ids=input_ids, position_ids=position_id  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 550 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>encoder_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.encoder(                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 551 │   │   │   </span>embedding_output,                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 552 │   │   │   </span>attention_mask=extended_attention_mask,                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 553 │   │   │   </span>head_mask=head_mask,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/models/mpnet/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_mp</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">net.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">332</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 329 │   │   </span>return_dict: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">bool</span> = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 330 │   │   </span>**kwargs,                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 331 │   </span>):                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 332 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>position_bias = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_position_bias(hidden_states)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 333 │   │   </span>all_hidden_states = () <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> output_hidden_states <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 334 │   │   </span>all_attentions = () <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> output_attentions <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 335 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i, layer_module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.layer):                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/models/mpnet/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_mp</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">net.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">379</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_position_bias</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 376 │   │   </span>rp_bucket = rp_bucket.to(x.device)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 377 │   │   </span>values = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.relative_attention_bias(rp_bucket)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 378 │   │   </span>values = values.permute([<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]).unsqueeze(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 379 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>values = values.expand((bsz, -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, qlen, klen)).contiguous()                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 380 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> values                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 381 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 382 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@staticmethod</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">216.00</span> MiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.93</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.24</span> GiB \n",
       "already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.56</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.43</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated memory\n",
       "try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_20007/\u001b[0m\u001b[1;33m4225333923.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_20007/4225333923.py'\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/langchain/vectorstores/\u001b[0m\u001b[1;33mchroma.py\u001b[0m:\u001b[94m446\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mfrom_documents\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m443 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m444 \u001b[0m\u001b[2m│   │   \u001b[0mtexts = [doc.page_content \u001b[94mfor\u001b[0m doc \u001b[95min\u001b[0m documents]                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m445 \u001b[0m\u001b[2m│   │   \u001b[0mmetadatas = [doc.metadata \u001b[94mfor\u001b[0m doc \u001b[95min\u001b[0m documents]                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m446 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mcls\u001b[0m.from_texts(                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m447 \u001b[0m\u001b[2m│   │   │   \u001b[0mtexts=texts,                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m448 \u001b[0m\u001b[2m│   │   │   \u001b[0membedding=embedding,                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m449 \u001b[0m\u001b[2m│   │   │   \u001b[0mmetadatas=metadatas,                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/langchain/vectorstores/\u001b[0m\u001b[1;33mchroma.py\u001b[0m:\u001b[94m414\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mfrom_texts\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m411 \u001b[0m\u001b[2m│   │   │   \u001b[0mclient_settings=client_settings,                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m412 \u001b[0m\u001b[2m│   │   │   \u001b[0mclient=client,                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m413 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m414 \u001b[2m│   │   \u001b[0mchroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m415 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m chroma_collection                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m416 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m417 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@classmethod\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/langchain/vectorstores/\u001b[0m\u001b[1;33mchroma.py\u001b[0m:\u001b[94m159\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92madd_texts\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   │   \u001b[0mids = [\u001b[96mstr\u001b[0m(uuid.uuid1()) \u001b[94mfor\u001b[0m _ \u001b[95min\u001b[0m texts]                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0membeddings = \u001b[94mNone\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._embedding_function \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m159 \u001b[2m│   │   │   \u001b[0membeddings = \u001b[96mself\u001b[0m._embedding_function.embed_documents(\u001b[96mlist\u001b[0m(texts))             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._collection.add(                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   │   │   \u001b[0mmetadatas=metadatas, embeddings=embeddings, documents=texts, ids=ids           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/langchain/embeddings/\u001b[0m\u001b[1;33mhuggingface.py\u001b[0m:\u001b[94m7\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m8\u001b[0m in \u001b[92membed_documents\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 75 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mList of embeddings, one for each text.\u001b[0m                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 76 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 77 \u001b[0m\u001b[2m│   │   \u001b[0mtexts = \u001b[96mlist\u001b[0m(\u001b[96mmap\u001b[0m(\u001b[94mlambda\u001b[0m x: x.replace(\u001b[33m\"\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33m \u001b[0m\u001b[33m\"\u001b[0m), texts))                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 78 \u001b[2m│   │   \u001b[0membeddings = \u001b[96mself\u001b[0m.client.encode(texts, **\u001b[96mself\u001b[0m.encode_kwargs)                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 79 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m embeddings.tolist()                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 80 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 81 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92membed_query\u001b[0m(\u001b[96mself\u001b[0m, text: \u001b[96mstr\u001b[0m) -> List[\u001b[96mfloat\u001b[0m]:                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/sentence_transformers/\u001b[0m\u001b[1;33mSentenceTransfo\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mrmer.py\u001b[0m:\u001b[94m165\u001b[0m in \u001b[92mencode\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   │   \u001b[0mfeatures = batch_to_device(features, device)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m165 \u001b[2m│   │   │   │   \u001b[0mout_features = \u001b[96mself\u001b[0m.forward(features)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m output_value == \u001b[33m'\u001b[0m\u001b[33mtoken_embeddings\u001b[0m\u001b[33m'\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0membeddings = []                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mcontainer.py\u001b[0m:\u001b[94m217\u001b[0m in  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m214 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# with Any as TorchScript expects a more precise type\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m215 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m):                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m216 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m217 \u001b[2m│   │   │   \u001b[0m\u001b[96minput\u001b[0m = module(\u001b[96minput\u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m218 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96minput\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m219 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m220 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mappend\u001b[0m(\u001b[96mself\u001b[0m, module: Module) -> \u001b[33m'\u001b[0m\u001b[33mSequential\u001b[0m\u001b[33m'\u001b[0m:                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/sentence_transformers/models/\u001b[0m\u001b[1;33mTransfor\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mmer.py\u001b[0m:\u001b[94m66\u001b[0m in \u001b[92mforward\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 63 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m'\u001b[0m\u001b[33mtoken_type_ids\u001b[0m\u001b[33m'\u001b[0m \u001b[95min\u001b[0m features:                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrans_features[\u001b[33m'\u001b[0m\u001b[33mtoken_type_ids\u001b[0m\u001b[33m'\u001b[0m] = features[\u001b[33m'\u001b[0m\u001b[33mtoken_type_ids\u001b[0m\u001b[33m'\u001b[0m]                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 66 \u001b[2m│   │   \u001b[0moutput_states = \u001b[96mself\u001b[0m.auto_model(**trans_features, return_dict=\u001b[94mFalse\u001b[0m)               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 67 \u001b[0m\u001b[2m│   │   \u001b[0moutput_tokens = output_states[\u001b[94m0\u001b[0m]                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 68 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 69 \u001b[0m\u001b[2m│   │   \u001b[0mfeatures.update({\u001b[33m'\u001b[0m\u001b[33mtoken_embeddings\u001b[0m\u001b[33m'\u001b[0m: output_tokens, \u001b[33m'\u001b[0m\u001b[33mattention_mask\u001b[0m\u001b[33m'\u001b[0m: features[\u001b[33m'\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/models/mpnet/\u001b[0m\u001b[1;33mmodeling_mp\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mnet.py\u001b[0m:\u001b[94m550\u001b[0m in \u001b[92mforward\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 547 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 548 \u001b[0m\u001b[2m│   │   \u001b[0mhead_mask = \u001b[96mself\u001b[0m.get_head_mask(head_mask, \u001b[96mself\u001b[0m.config.num_hidden_layers)          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 549 \u001b[0m\u001b[2m│   │   \u001b[0membedding_output = \u001b[96mself\u001b[0m.embeddings(input_ids=input_ids, position_ids=position_id  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 550 \u001b[2m│   │   \u001b[0mencoder_outputs = \u001b[96mself\u001b[0m.encoder(                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 551 \u001b[0m\u001b[2m│   │   │   \u001b[0membedding_output,                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 552 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=extended_attention_mask,                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 553 \u001b[0m\u001b[2m│   │   │   \u001b[0mhead_mask=head_mask,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/models/mpnet/\u001b[0m\u001b[1;33mmodeling_mp\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mnet.py\u001b[0m:\u001b[94m332\u001b[0m in \u001b[92mforward\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 329 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict: \u001b[96mbool\u001b[0m = \u001b[94mFalse\u001b[0m,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 330 \u001b[0m\u001b[2m│   │   \u001b[0m**kwargs,                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 331 \u001b[0m\u001b[2m│   \u001b[0m):                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 332 \u001b[2m│   │   \u001b[0mposition_bias = \u001b[96mself\u001b[0m.compute_position_bias(hidden_states)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 333 \u001b[0m\u001b[2m│   │   \u001b[0mall_hidden_states = () \u001b[94mif\u001b[0m output_hidden_states \u001b[94melse\u001b[0m \u001b[94mNone\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 334 \u001b[0m\u001b[2m│   │   \u001b[0mall_attentions = () \u001b[94mif\u001b[0m output_attentions \u001b[94melse\u001b[0m \u001b[94mNone\u001b[0m                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 335 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m i, layer_module \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(\u001b[96mself\u001b[0m.layer):                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/arr/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/models/mpnet/\u001b[0m\u001b[1;33mmodeling_mp\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mnet.py\u001b[0m:\u001b[94m379\u001b[0m in \u001b[92mcompute_position_bias\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 376 \u001b[0m\u001b[2m│   │   \u001b[0mrp_bucket = rp_bucket.to(x.device)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 377 \u001b[0m\u001b[2m│   │   \u001b[0mvalues = \u001b[96mself\u001b[0m.relative_attention_bias(rp_bucket)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 378 \u001b[0m\u001b[2m│   │   \u001b[0mvalues = values.permute([\u001b[94m2\u001b[0m, \u001b[94m0\u001b[0m, \u001b[94m1\u001b[0m]).unsqueeze(\u001b[94m0\u001b[0m)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 379 \u001b[2m│   │   \u001b[0mvalues = values.expand((bsz, -\u001b[94m1\u001b[0m, qlen, klen)).contiguous()                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 380 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m values                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 381 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 382 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@staticmethod\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m216.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m5.93\u001b[0m GiB total capacity; \u001b[1;36m5.24\u001b[0m GiB \n",
       "already allocated; \u001b[1;36m10.56\u001b[0m MiB free; \u001b[1;36m5.43\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory\n",
       "try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_20007/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2024515612.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_20007/2024515612.py'</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'vectorstore'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_20007/\u001b[0m\u001b[1;33m2024515612.py\u001b[0m:\u001b[94m4\u001b[0m in \u001b[92m<module>\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_20007/2024515612.py'\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'vectorstore'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(llm,\n",
    "                                           vectorstore.as_retriever(),\n",
    "                                           return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_20007/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1647439059.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_20007/1647439059.py'</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'qa'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_20007/\u001b[0m\u001b[1;33m1647439059.py\u001b[0m:\u001b[94m4\u001b[0m in \u001b[92m<module>\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_20007/1647439059.py'\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'qa'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "query = \"What is the definition of intelligence?\"\n",
    "result = qa({\"question\":query, \"chat_history\":chat_history})\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
